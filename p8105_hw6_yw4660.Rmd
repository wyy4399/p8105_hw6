---
title: "p8105_hw6_yw4660"
output: 
  github_document:
  html_document:
---

```{r import library, include=FALSE}
library(tidyverse)
library(ggplot2)
```
## Problem 1
```{r p1}
homicides <- read_csv(
  "data/homicide-data.csv",
  locale = locale(encoding = "ISO-8859-1")
)
#skimr::skim(homicides)
homicides <- homicides |>
  mutate(
    city_state = paste(city, state, sep = ", "),
    solved = disposition == "Closed by arrest",
    victim_age  = as.numeric(victim_age)
  ) |>
  
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ",
                        "Kansas City, MO", "Tulsa, AL"))
  ) |>
  filter(victim_race %in% c("White", "Black")) |>
  filter(victim_sex %in% c("Male", "Female")) |>
  filter(
    !is.na(solved),
    !is.na(victim_age),
    !is.na(victim_sex),
    !is.na(victim_race)
  ) |>
  mutate(
    victim_sex  = fct_relevel(victim_sex, "Female"),
    victim_race = fct_relevel(victim_race, "White")
  )
# logistic regression for baltimore
baltimore <- homicides |>
  filter(city_state == "Baltimore, MD")
baltimore_glm <- glm(
  solved ~ victim_age + victim_sex + victim_race,
  data   = baltimore,
  family = binomial()
)
baltimore_or <- broom::tidy(baltimore_glm, conf.int = TRUE) |>
  mutate(
    or     = exp(estimate),
    or_low = exp(conf.low),
    or_hi  = exp(conf.high)
  ) |>
  filter(term == "victim_sexMale") |>
  select(term, or, or_low, or_hi)
baltimore_or
# glm for cities
city_models <- homicides |>
  nest(data = -city_state) |>
  mutate(n = map_int(data, nrow),
     model = map(data,
      ~ glm(
        solved ~ victim_age + victim_sex + victim_race,
        data   = .x,
        family = binomial()
        )
    ),
     results = map(
      model,
      ~ broom::tidy(.x, conf.int = TRUE) |>
        mutate(
          or     = exp(estimate),
          or_low = exp(conf.low),
          or_hi  = exp(conf.high)
        )
    )
  )
city_or <- city_models |>
  select(city_state, n, results) |>
  unnest(results) |>
  filter(term == "victim_sexMale") |>
  select(city_state, n, or, or_low = or_low, or_hi = or_hi)
  
city_or |>
  arrange(desc(or)) |>
  print(n = 10)
# plot of or
city_or |>
  mutate(
    city_state = fct_reorder(city_state, or)
  ) |>
  ggplot(aes(x = or, y = city_state)) +
  geom_point() +
  geom_errorbar(aes(xmin = or_low, xmax = or_hi), width = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  labs(
    x = "Adjusted odds ratio (Male vs Female)",
    y = "City",
    title = "Adjusted OR for solving homicides by victim sex\n(controls: age, race)"
  ) +
  theme_minimal()
```

## Problem 2

```{r p2 bootstrap distribution}
library(tidyverse)
library(p8105.datasets)
library(broom)
library(modelr) 

data("weather_df")

weather_boot_df <- weather_df |>
  select(tmax, tmin, prcp) |>
  drop_na()

set.seed(42)
n_boot <- 5000

boot_results <- weather_boot_df |>
  modelr::bootstrap(n = n_boot) |>
  mutate(
    model = map(strap, ~ lm(tmax ~ tmin + prcp, data = as_tibble(.x))),
    glance = map(model, glance),
    tidy   = map(model, tidy),
    
    # r2
    r_squared = map_dbl(glance, "r.squared"),
    # beta
    beta_ratio = map_dbl(
      tidy,
      ~ {
        coefs <- .x |>
          filter(term %in% c("tmin", "prcp")) |>
          select(term, estimate)
        
        b1 <- coefs |> filter(term == "tmin") |> pull(estimate)
        b2 <- coefs |> filter(term == "prcp") |> pull(estimate)
        
        b1 / b2
      }
    )
  ) |>
  select(.id, r_squared, beta_ratio)

# boot_results |> head()

boot_results |>
  pivot_longer(
    cols = c(r_squared, beta_ratio),
    names_to = "quantity",
    values_to = "estimate"
  ) |>
  mutate(
    quantity = recode(
      quantity,
      r_squared = "R^2",
      beta_ratio = "beta1 / beta2"
    )
  ) |>
  ggplot(aes(x = estimate)) +
  geom_histogram(bins = 50) +
  facet_wrap(~ quantity, scales = "free") +
  labs(
    x = "Bootstrap estimate",
    y = "Count",
    title = "Bootstrap distributions for R^2 and beta1 / beta2"
  ) +
  theme_minimal()
```
The bootstrap distribution of $R^2$ is approximately symmetric and very concentrated around 0.942, indicating that tmin and prcp together explain a large and fairly stable proportion of the variability in tmax. The bootstrap distribution of $\frac{\hat{\beta}_1}{\hat{\beta}_2}$ is centered around about −180, with a noticeably wider spread, suggesting more uncertainty in this ratio of coefficients.
```{r p2 confidence interval}
boot_summary <- boot_results |>
  summarise(
    r2_mean    = mean(r_squared),
    r2_ci_low  = quantile(r_squared, 0.025),
    r2_ci_high = quantile(r_squared, 0.975),
    
    ratio_mean    = mean(beta_ratio),
    ratio_ci_low  = quantile(beta_ratio, 0.025),
    ratio_ci_high = quantile(beta_ratio, 0.975)
  )

boot_summary
```
Based on the bootstrap samples, the 95% percentile confidence interval for $R^2$ is roughly (0.935, 0.947), and the corresponding interval for $\frac{\hat{\beta}_1}{\hat{\beta}_2}$ is approximately (−281, −125). These intervals summarize the sampling variability of the two quantities under the bootstrap procedure.

## Problem3

```{r p3}
birth <- read.csv("data/birthweight.csv")

birth_clean <- birth |>
  mutate(
    babysex = factor(babysex, levels = c(1,2), labels = c("male","female")),
    frace   = factor(frace),
    mrace   = factor(mrace),
    malform = factor(malform, levels = c(0,1), labels = c("absent","present")),
    parity  = factor(parity),
    fincome = as.numeric(fincome),
    gaweeks = as.numeric(gaweeks)
  ) |>
  drop_na()
# skimr::skim(birth_clean)
# glimpse(birth_clean)
```

### model a

```{r model a}
mod_A <- lm(
  bwt ~ babysex + blength + gaweeks + ppbmi + smoken + fincome + mrace,
  data = birth_clean
)

summary(mod_A)
# add prediction and residual
birth_clean|>
  add_predictions(mod_A) |>
  add_residuals(mod_A) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Residuals vs fitted values for Model A",
    x = "Fitted birthweight",
    y = "Residuals"
  ) +
  theme_minimal()
```

### model b and model c

```{r model b and model c}
mod_B <- lm(
  bwt ~ blength + gaweeks,
  data = birth_clean
)

mod_C <- lm(
  bwt ~ bhead * blength * babysex,
  data = birth_clean
)
summary(mod_B)
summary(mod_C)
```

### cv

```{r cv}
set.seed(42)

cv_df <- crossv_mc(birth_clean, n = 100)

cv_results <- cv_df |>
  mutate(
    train = map(train, as_tibble),
    test  = map(test,  as_tibble),

    fit_A = map(train, ~ lm(
      bwt ~ babysex + blength + gaweeks + ppbmi + smoken + fincome + mrace,
      data = .x)),
    fit_B = map(train, ~ lm(
      bwt ~ blength + gaweeks,
      data = .x)),
    fit_C = map(train, ~ lm(
      bwt ~ bhead * blength * babysex,
      data = .x)),

    rmse_A = map2_dbl(fit_A, test, ~ rmse(model = .x, data = .y)),
    rmse_B = map2_dbl(fit_B, test, ~ rmse(model = .x, data = .y)),
    rmse_C = map2_dbl(fit_C, test, ~ rmse(model = .x, data = .y))
  )


cv_summary <- cv_results |>
  select(starts_with("rmse_")) |>
  pivot_longer(
    cols = everything(),
    names_to = "model",
    values_to = "rmse"
  ) |>
  mutate(
    model = recode(
      model,
      rmse_A = "Model A (main)",
      rmse_B = "Model B (length + gaweeks)",
      rmse_C = "Model C (bhead*blength*babysex)"
    )
  ) |>
  group_by(model) |>
  summarise(
    mean_rmse = mean(rmse),
    sd_rmse   = sd(rmse),
    .groups   = "drop"
  )

cv_summary

```

Across the 100 Monte-Carlo cross-validation splits, Model C has the lowest mean RMSE, indicating the best predictive performance among the three models. Model A performs moderately well, with slightly higher prediction error, while Model B shows the largest RMSE and therefore the weakest predictive ability. Overall, incorporating interactions among head circumference, length, and sex (Model C) appears to improve prediction accuracy relative to the simpler models.
